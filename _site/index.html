<!DOCTYPE HTML>
<html lang="en">

<head>
  <title>Chuer Pan</title>

  <meta content="text/html; charset=utf-8" http-equiv="Content-Type">

  <meta name="author" content="Chuer Pan" />
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="/style.css" />
  <link rel="canonical" href="http://localhost:4000/">
  <link href="https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css">

</head>



<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr style="padding:0px">
            <td style="padding:2.5%;width:60%;vertical-align:middle">
              <h1>
                Chuer Pan
              </h1>
              <p>Hello there! I am a Research Assistant at the <a href="https://www.ri.cmu.edu/ri-people/chuer-pan/">Robotics Institute</a>, Carnegie Mellon University, 
                where I work as a member of the <a href="https://r-pad.github.io/">Robots Perceiving and Doing Lab</a> with <a href="https://davheld.github.io/">David Held</a>.
              </p>
              <p>
                I am interested in developing systems that enable robots to perform dynamic, complex manipulation tasks by learning to extract task-relevant semantic visual cues efficiently from limited demonstrations. 
                <!-- Currently, I work on developing learning-based self-supervised systems to robustly perform high-precision manipulation tasks, such as hanging mugs on mug racks, via imbuing desirable properties into object pose representation for multi-object manipulation tasks. -->
              </p>
              <p>
                I obtained my <a href="https://www.ri.cmu.edu/education/academic-programs/master-of-science-robotics/">MS in Robotics</a> from Robotics Institute at Carnegie Mellon University, where I worked on robot learning for manipulation with <a href="https://davheld.github.io/">David Held</a>. 
                Before that, I did my BASc in <a href="https://engsci.utoronto.ca/program/what-is-engsci/">Engineering Science</a> at the University of Toronto, specializing in Robotics. 
                There, I worked on deep natural language processing with <a href="http://www.cs.toronto.edu/~frank/">Frank Rudzicz</a> at <a href="https://vectorinstitute.ai/">Vector Institute</a>. 
                I also worked on microfabrication for microfluidics with <a href="https://sites.chem.utoronto.ca/chemistry/staff/EK/about.html">Eugenia Kumacheva</a> during early exposure to research.
              </p>
              <p>
                During undergrad, I implemented motion planning algorithms to enable an automous vehicle to adhere to traffic rules while handling static/dynamic obstacles for <a href="https://www.autodrive.utoronto.ca/">aUToronto</a>, University of Toronto's Student Self-Driving Team that competed in SAE AutoDrive Challenge.
              </p>

              <p style="text-align:center">
                Email: chuer.pan at gmail.com
              </p>
              <p style="text-align:center">
                <a href="https://scholar.google.com/citations?user=HBMZ02EAAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                <a href="https://www.linkedin.com/in/chuer-pan-a2ab0475/">LinkedIn </a> &nbsp;/&nbsp;
                <a href="https://github.com/mimichu">GitHub</a> &nbsp;/&nbsp;
                <a href="/files/Chuer_Pan_Resume.pdf">CV</a>
                
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <img style="width:100%;max-width:100%" alt="profile photo" src="images/circle_bw_crop.jpg">
            </td>
          </tr>
        </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:100%;vertical-align:middle">
              <h2>Research</h2>
              <p>
                I'm interested in robotics, machine learning and computer vision.
              </p>
            </td>
          </tr>
        </table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">

          
          
          
          <tr>
            <td style="padding:2.5%;width:50%;vertical-align:middle;min-width:120px">
              <img src="/images/taxpose.gif" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>TAX-Pose: Task-Specific Cross-Pose Estimation for Robot Manipulation</h3>
              <br>
              <strong>Chuer Pan*</strong>, Brian Okorn*, Harry Zhang*, Ben Eisner*, David Held

              <br>
              <em>Conference on Robot Learning (CoRL)</em>, 2022
              <br>
              
              <a href="https://openreview.net/pdf?id=FlGPw9g5v1">paper</a> /
              
              
              <a href="https://sites.google.com/view/tax-pose/home">website</a> /
              
              
              
              
              <p></p>
              <p>We propose a vision-based system that learns to estimate the task specific pose relationship (cross-pose) between pairs of interacting object using learned cross-object correspondences. We demonstrate that our method is able to learn from just 10 real point cloud demonstration with no pose annotations needed and generalize to novel instances within the trained object category.</p>

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:50%;vertical-align:middle;min-width:120px">
              <img src="/images/mrp.gif" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Deep Projective Rotation Estimation through Relative Supervision</h3>
              <br>
              Brian Okorn*, <strong>Chuer Pan*</strong>, Martial Herbert, David Held

              <br>
              <em>Conference on Robot Learning (CoRL)</em>, 2022
              <br>
              
              <a href="https://openreview.net/pdf?id=Z1Kg3RNv3M5">paper</a> /
              
              
              <a href="https://sites.google.com/view/deep-projective-rotation/home">website</a> /
              
              
              
              
              <p></p>
              <p>We propose a new algorithm for self-supervised orientation estimation which utilizes Modified Rodrigues Parameters to stereographically project the closed manifold of SO(3) to the open manifold of 3D Euclidean space, which avoids the local optima common when naively applying relative self-supervision for object orientation estimation, allowing for faster convergence and lower rotational error on relative rotation estimation.</p>

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:50%;vertical-align:middle;min-width:120px">
              <img src="/images/rst.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>Examining the rhetorical capacities of neural language models</h3>
              <br>
              Zining Zhu, <strong>Chuer Pan</strong>, Mohamed Abdalla, Frank Rudzicz

              <br>
              <em>Conference on Empirical Methods in Natural Language Processing (EMNLP) BlackboxNLP Workshop</em>, 2020
              <br>
              
              <a href="https://aclanthology.org/2020.blackboxnlp-1.3/">paper</a> /
              
              
              
              <a href="https://www.youtube.com/watch?v=cmDc1HuGKWE">video</a> /
              
              
              
              <p></p>
              <p>We propose a method that quantitatively evaluates the rhetorical capacities of neural language models (LMs) by evaluating their abilities to encode a set of linguistic features derived from Rhetorical Structure Theory (RST). Our experiments show that BERT-based LMs outperform other Transformer LMs such as GPT-2 and XLNet, revealing richer discourse knowledge in their intermediate layer representations.</p>

            </td>
          </tr>
          
          
          
          
          
          <tr>
            <td style="padding:2.5%;width:50%;vertical-align:middle;min-width:120px">
              <img src="/images/microfab1.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <h3>An exploration of the reflow technique for the fabrication of an in vitro microvascular system to study occlusive clots</h3>
              <br>
              Yang Li, <strong>Chuer Pan</strong>, Yunfeng Li, Eugenia Kumacheva, Arun Ramachandran

              <br>
              <em>Biomedical Microdevices, 19(4), 1-16</em>, 2017
              <br>
              
              <a href="https://link.springer.com/article/10.1007/s10544-017-0213-0">paper</a> /
              
              
              
              
              
              <p></p>
              <p>We introduce a reflow technique for fabrication of multi-level microchannel network with circular cross-section to systematically study the dissolution effects of thrombolytic drug on occlusive embolic clots in microvascular system.</p>

            </td>
          </tr>
          
          
          
        </table>
        <br>
        <br>
        <br>
   
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">
                Design and source code from <a style="font-size:small;" href="https://jonbarron.info">Jon Barron's website</a>
              </p>
            </td>
          </tr>
        </table>
      </td>
    </tr>
  </table>
</body>

</html>

